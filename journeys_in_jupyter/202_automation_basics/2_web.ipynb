{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"https://github.com/theonaunheim\">\n",
    "    <img style=\"border-radius: 100%; float: right;\" src=\"static/strawberry_thief_square.png\" width=10% alt=\"Theo Naunheim's Github\">\n",
    "</a>\n",
    "<br style=\"clear: both\">\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "<h1 align='center'>Web</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: table; width: 100%\">\n",
    "    <div style=\"display: table-row; width: 100%;\">\n",
    "        <div style=\"display: table-cell; width: 50%; vertical-align: middle;\">\n",
    "            <img src=\"static/internet.jpg\" width=\"300\">\n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 10%\">\n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 40%; vertical-align: top;\">\n",
    "            <blockquote>\n",
    "                <p style=\"font-style: italic;\">\"lo\"</p>\n",
    "                <br>\n",
    "                <p>-The first message sent on the Internet</p>\n",
    "                <br>\n",
    "                <p style=\"font-style: italic;\">\"login\"</p>\n",
    "                <br>\n",
    "                <p>-The second message sent on the Internet (one hour after the first message sent on the Internet crashed the Internet)</p>\n",
    "            </blockquote>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='left'>\n",
    "    Image courtesy of <a href='https://commons.wikimedia.org/wiki/Category:Internet#/media/File:Internet_map_1024.jpg'>The Opte Project</a> under the <a href='https://creativecommons.org/licenses/by/2.5/'>CC 2.5 BY</a>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generally\n",
    "\n",
    "Python cut its teeth in the internet age, and consequently its standard library and third party packages have web capabilities. This is going to cover some of the more common operations you'll see that involve client-side web programming. In other words: fetching from websites, parsing, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Modules covered\n",
    "\n",
    "### Standard Library\n",
    "* [email](https://docs.python.org/3.4/library/email.html#module-email)\n",
    "* [json](https://docs.python.org/3/library/json.html)\n",
    "* [pathlib](https://docs.python.org/3/library/pathlib.html)\n",
    "* [smtplib](https://docs.python.org/3/library/smtplib.html)\n",
    "* [urllib.request](https://docs.python.org/3/library/urllib.request.html#module-urllib.request)\n",
    "* [urllib.parse](https://docs.python.org/3/library/urllib.parse.html)\n",
    "* [webbrowser](https://docs.python.org/3/library/webbrowser.html)\n",
    "\n",
    "### Third Party Libraries\n",
    "* [beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [comtypes.client](https://pythonhosted.org/comtypes/)\n",
    "* [requests](http://docs.python-requests.org/en/master/)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "\n",
    "\n",
    "# Modules not covered\n",
    "\n",
    "### Standard Library\n",
    "* [ftplib](https://docs.python.org/3/library/ftplib.html)\n",
    "* [xml](https://docs.python.org/3/library/xml.html)\n",
    "\n",
    "### Third Party Libraries\n",
    "* [selenium](http://selenium-python.readthedocs.io/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stdlib imports\n",
    "import email.mime.text\n",
    "import json\n",
    "import pathlib\n",
    "import smtplib\n",
    "import urllib.request\n",
    "import webbrowser\n",
    "\n",
    "# Third party imports\n",
    "import bs4\n",
    "import comtypes.client \n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Web Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching web pages using the the standard library. \n",
    "\n",
    "Note: this is for sites outside the bank. Sites inside the bank will require special authentication mechanisms.\n",
    "\n",
    "Note: at times, the proxies can be finnicky. \"Rerun login scripts\" often helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a URL\n",
    "HTTPS_URL = 'https://en.wikipedia.org/wiki/Monty_Python_and_the_Holy_Grail'\n",
    "\n",
    "# Open the request\n",
    "r = urllib.request.urlopen(HTTPS_URL)\n",
    "\n",
    "# Check the status of my request\n",
    "status_code = r.getcode()\n",
    "print('The status of my request is {}!\\n\\n'.format(status_code))\n",
    "\n",
    "# Convert the raw bytes to text\n",
    "raw_data = r.read()\n",
    "text_data = raw_data.decode()\n",
    "\n",
    "# Do stuff with HTML output\n",
    "print('Here is the start of our data from {} !\\n\\n'.format(HTTPS_URL))\n",
    "print(text_data[:100])\n",
    "\n",
    "# Close request\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Though it's better to do it like this with a context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the above again as a context manager:\n",
    "with urllib.request.urlopen(HTTPS_URL) as f:\n",
    "    text_data = f.read().decode()\n",
    "    \n",
    "print('\\n\\n\\nHere is the data again!\\n\\n\\n{}'.format(text_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also download files as necessary and put them in RAM or write them to the filesystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a URL\n",
    "FOOT_URL = 'https://upload.wikimedia.org/wikipedia/commons/a/ab/Monty_python_foot.png'\n",
    "FOOT_OUT = './static/monty_python_foot.png'\n",
    "\n",
    "# Download data\n",
    "with urllib.request.urlopen(FOOT_URL) as f:\n",
    "    binary_data = f.read()\n",
    "\n",
    "# Write data to a file.\n",
    "with open(FOOT_OUT, 'wb') as f:\n",
    "    f.write(binary_data)\n",
    "    \n",
    "# Or to a temporary buffer-like interface like io.BytesIO or tempfile.TemporaryFile\n",
    "# Output using keyword args (not necessary)\n",
    "args = {\n",
    "    'length': len(binary_data), \n",
    "    'url': FOOT_URL, \n",
    "    'dest': FOOT_OUT\n",
    "}\n",
    "print('We downloaded {length} bytes of data from {url} , and wrote it to {dest}!'.format(**args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed you can break it into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data using an infinite loop (generally a bad idea)\n",
    "with open(FOOT_OUT, 'wb') as out_file:\n",
    "    # Nested context manager\n",
    "    with urllib.request.urlopen(FOOT_URL) as web_file:\n",
    "        # Infinite loop\n",
    "        while True:\n",
    "            # Read data\n",
    "            binary_data = web_file.read(8192)\n",
    "            # If no data left, will be None and loop will break.\n",
    "            if not binary_data:\n",
    "                break\n",
    "            # Write data\n",
    "            out_file.write(binary_data)\n",
    "            print('.', end='')\n",
    "        print('\\nDing! Loops are done.')\n",
    "    # Web connection closes here\n",
    "# Binary file closes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usually the \"requests\" module, which describes itself as \"HTTP for Humans\" is easier, but it can sometimes run afoul of proxy servers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certificate location (this will not work for you)\n",
    "TARGET_URL = 'https://www.google.com'\n",
    "\n",
    "# You do not have this file on your desktop.\n",
    "CERT_PATH = 'FULL_PATH_TO_CERT.cer' \n",
    "\n",
    "# Open the request\n",
    "r = requests.get(TARGET_URL, verify=CERT_PATH)\n",
    "\n",
    "# Stop if error\n",
    "r.raise_for_status()\n",
    "\n",
    "# As text\n",
    "text = r.text\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have HTML, you can get to scraping using beautifulsoup (\"bs4\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your soup\n",
    "soup = bs4.BeautifulSoup(text_data, 'lxml')\n",
    "\n",
    "# Iterate through all the tables to get our table\n",
    "for table in soup.find_all('table'):\n",
    "    # Check if it's the table we want\n",
    "    if 'wikitable' in table.attrs['class']:\n",
    "        target_table = table\n",
    "\n",
    "# Alternatvely we can get it directly\n",
    "target_table = soup.select('table.wikitable')[0]\n",
    "print(str(target_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open_new('https://en.wikipedia.org/wiki/Monty_Python_and_the_Holy_Grail#Cast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And put it in a dataframe for organized manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our table, convert it to something we can use.\n",
    "df = pd.read_html(str(target_table), header=0)[0]\n",
    "\n",
    "# Don't even try to understand this, but here the formatting is weird.\n",
    "table_data = [\n",
    "    [\n",
    "        cell.find('span').text\n",
    "        if cell.find('span')\n",
    "        else cell.text\n",
    "        for cell\n",
    "        in row.find_all(['th', 'td'])\n",
    "    ]\n",
    "    for row\n",
    "    in target_table.find_all('tr')\n",
    "]\n",
    "\n",
    "# Coerce to dataframe\n",
    "df = pd.DataFrame.from_records(table_data[1:], columns=table_data[0])\n",
    "\n",
    "# Do arbitrary stuff to our data.\n",
    "df['LAST_NAME'] = df['Actor\\n'].str.split(',').str.get(0)\n",
    "df['FIRST_NAME'] = df['Actor\\n'].str.split(',').str.get(1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or if we want to crawl, we can get the links and go from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can manually put in the base\n",
    "base = 'https://en.wikipedia.org'\n",
    "\n",
    "# Or we can get it more generally\n",
    "url_obj = urllib.parse.urlsplit(HTTPS_URL)\n",
    "base = url_obj.scheme + '://' + url_obj.hostname\n",
    "\n",
    "# Get all links.\n",
    "links = []\n",
    "for link in soup.find_all('a'):\n",
    "    try:\n",
    "        new_url = base + link.attrs['href']\n",
    "        if link.attrs['href'].startswith('http'):\n",
    "            pass\n",
    "        links.append(new_url)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where this really comes into its own is with REST APIs to fetch structured data from the internets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFPB_ENDPOINT = 'https://data.consumerfinance.gov/resource/jhzv-w97w.json?'\n",
    "\n",
    "QUERY_ARGS = {\n",
    "    'state'   : 'MO',\n",
    "    'product' : 'Credit card'\n",
    "}\n",
    "\n",
    "# Let's construct our REST query string\n",
    "query_string = urllib.parse.urlencode(QUERY_ARGS)\n",
    "full_url = CFPB_ENDPOINT + query_string\n",
    "\n",
    "print('We are querying: {} !\\n\\n'.format(full_url))\n",
    "\n",
    "# And then fetch our data\n",
    "with urllib.request.urlopen(full_url) as f:\n",
    "    json_data = f.read().decode()\n",
    "\n",
    "# We can load this into native Python datatypes\n",
    "data = json.loads(json_data)\n",
    "print(data[0])\n",
    "print('\\n\\n')\n",
    "\n",
    "# Or we can immediately go to pandas.\n",
    "df = pd.read_json(json_data)\n",
    "\n",
    "# And refine as needed.\n",
    "df.dropna(subset=['complaint_what_happened']).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### And again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "FEMA_URL = 'http://www.fema.gov/api/open/v1/DisasterDeclarationsSummaries?$filter=declarationDate%20gt%20\\'{}\\''\n",
    "\n",
    "# Let's construct our REST query string\n",
    "pd.datetime.now().date().isoformat()\n",
    "now = pd.datetime.now()\n",
    "# We can use all the handy libraries of Python!\n",
    "one_hundred_bdays_ago = now - pd.tseries.offsets.BusinessDay(100)\n",
    "date = one_hundred_bdays_ago.date()\n",
    "iso_date = date.isoformat()\n",
    "full_url = FEMA_URL.format(iso_date)\n",
    "\n",
    "print('Querying {} !'.format(full_url))\n",
    "\n",
    "# And then fetch our data\n",
    "with urllib.request.urlopen(full_url) as f:\n",
    "    json_data = f.read().decode()\n",
    "    data = json.loads(json_data)\n",
    "\n",
    "df = pd.DataFrame(data['DisasterDeclarationsSummaries'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We can also email stuff.\n",
    "\n",
    "Note: the method below requires MS Outlook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also email stuff\n",
    "STRING_OF_RECIPIENTS = '''\n",
    "<theonaunheim@gmail.com>;\n",
    "'''\n",
    "\n",
    "# Easy way to extract emails from formatted string\n",
    "recipient_series = pd.Series([STRING_OF_RECIPIENTS])\n",
    "extracted_emails = recipient_series.str.extractall(\"<(.*?)>\")\n",
    "email_addresses = extracted_emails[0].values\n",
    "\n",
    "# Send table\n",
    "table_html = table_content=df.head(5)[['declarationDate', 'declaredCountyArea']].to_html()\n",
    "\n",
    "EMAIL_HTML = '''\n",
    "\n",
    "<head>\n",
    "\n",
    "    <style type=\"text/css\">\n",
    "    \n",
    "        body, table, td {{font-family: Segoe UI, sans-serif !important; color: #34282C;}}\n",
    "        table {{border-width: 20px; width: 100%;}}\n",
    "        th, td {{text-align: left; padding: 8px; border: 1px solid white; border-collapse: collapse; }}\n",
    "        th {{background-color: #000080; color: white;}}\n",
    "\n",
    "    </style>\n",
    "\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "    <p>\n",
    "        <h1>Automated email sent from Python automation presentation.</h1><br>\n",
    "        <span>\n",
    "            <img src=\"cid:{img_path}\" width=\"100\" alt=\"foot\">\n",
    "            <img src=\"cid:{img_path}\" width=\"100\" alt=\"foot\">\n",
    "        </span>\n",
    "        <br>\n",
    "        I met a traveller from an antique land<br>\n",
    "        Who said: Two vast and trunkless legs of stone<br>\n",
    "        Stand in the desert ... near them, on the sand,<br>\n",
    "        Half sunk, a shattered visage lies, whose frown,<br>\n",
    "        And wrinkled lip, and sneer of cold command,<br>\n",
    "        Tell that its sculptor well those passions read<br>\n",
    "        Which yet survive, stamped on these lifeless things,<br>\n",
    "        The hand that mocked them and the heart that fed;<br>\n",
    "        <br>\n",
    "        And on the pedestal these words appear:<br>\n",
    "        'My name is Ozymandias, king of kings;<br>\n",
    "        Look on my works, ye Mighty, and despair!'<br>\n",
    "        Nothing beside remains. Round the decay<br>\n",
    "        Of that colossal wreck, boundless and bare<br>\n",
    "        The lone and level sands stretch far away.<br>\n",
    "        <br>\n",
    "    </p>\n",
    "\n",
    "    {table_content}\n",
    "\n",
    "</body>\n",
    "\n",
    "'''.format(\n",
    "    table_content=table_html,\n",
    "    img_path=str(pathlib.Path(FOOT_OUT).name)\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Create an application object\n",
    "    outlook = comtypes.client.CreateObject(\"Outlook.Application\")\n",
    "\n",
    "    # Create your email\n",
    "    mail = outlook.CreateItem(0)\n",
    "    mail.To = ';'.join(email_addresses)\n",
    "    mail.Subject = 'Ozymandias'\n",
    "\n",
    "    # Add body and attachemnts\n",
    "    mail.HTMLBody = EMAIL_HTML\n",
    "    veggie_csv = pathlib.Path(FOOT_OUT).parent.parent.absolute() / 'data' / 'iris_dataset.csv'\n",
    "    mail.Attachments.Add(str(veggie_csv.absolute()))\n",
    "    mail.Attachments.Add(str(pathlib.Path(FOOT_OUT).absolute()))\n",
    "    # mail.CC = 'recipient1@usbank.com; recipient2@usbank.com'\n",
    "    # mail.BlindCopyTo = \"alice_bob@usbank.com\"\n",
    "\n",
    "    # Send your mail\n",
    "    mail.Send()\n",
    "    # outlook.Quit() # you will probably want to keep this open.\n",
    "except Exception as e:\n",
    "    raise Exception(\"Something went wrong, but I have no idea what is happening on your particular machine. :\" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's generally preferable to send it directly via server, but that takes some prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct your email message\n",
    "# msg = email.mime.text.MIMEText(EMAIL_HTML, 'html') \n",
    "# msg['Subject'] = 'Ozymandias' \n",
    "# msg['From'] = 'Percy Bysshe Shelley' \n",
    "# msg['To'] = ','.join(LIST_OF_RECIPIENTS) \n",
    "\n",
    "# Send msg (this is the test server below, your server may differ). \n",
    "# s = smtplib.SMTP(host='server', port=25) \n",
    "# s.sendmail(msg['From'], msg['To'], msg.as_string()) \n",
    "# s.quit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Learing Resources\n",
    "\n",
    "* ### [Webscraping on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2015/10/beginner-guide-web-scraping-beautiful-soup-python/)\n",
    "* ### [Webscraping on Hitchhiker's Guide to Python](http://docs.python-guide.org/en/latest/scenarios/scrape/)\n",
    "* ### [Email Examples in Python Documentation](https://docs.python.org/3.4/library/email-examples.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Next Up: [Database](3_database.ipynb)\n",
    "\n",
    "<br>\n",
    "\n",
    "<img style=\"margin-left: 0;\" src=\"static/database.png\" width=\"20%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='left'>\n",
    "    Image courtesy of <a href='https://commons.wikimedia.org/wiki/File:Applications-database.svg'>Dracos</a> under the <a href='https://creativecommons.org/licenses/by-sa/3.0/deed.en'>CC BY-SA 3.0</a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
