{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"https://github.com/theonaunheim\">\n",
    "    <img style=\"border-radius: 100%; float: right;\" src=\"static/strawberry_thief_square.png\" width=10% alt=\"Theo Naunheim's Github\">\n",
    "</a>\n",
    "\n",
    "<br style=\"clear: both\">\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "<h1 align='center'>Concepts</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: table; width: 100%\">\n",
    "    <div style=\"display: table-row; width: 100%;\">\n",
    "        <div style=\"display: table-cell; width: 50%; vertical-align: middle;\">\n",
    "            <img src=\"static/gradient_ascent.png\" width=\"400\">\n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 10%\">\n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 40%; vertical-align: top;\">\n",
    "            <blockquote>\n",
    "                <p style=\"font-style: italic;\">\"Diligence is the mother of good fortune.\"</p>\n",
    "                <br>\n",
    "                <p>-Miguel de Cervantes</p>\n",
    "             </blockquote>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='left'>\n",
    "    Image courtesy of <a href='https://commons.wikimedia.org/wiki/File:Gradient_ascent_(surface).png'>Joris Gillis</a>; released into the public domain.\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff so we can use libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "from IPython.display import Latex\n",
    "from IPython.display import Markdown\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generally\n",
    "\n",
    "[Machine learning (ML)](https://en.wikipedia.org/wiki/Machine_learning) is a subset of [artificial intelligence (AI)](https://en.wikipedia.org/wiki/Artificial_intelligence) that covers a huge body of knowledge. This presentation doesn't even start to cover everything, but will hopefully will give you enough to point you in the right direction so you can learn more.\n",
    "\n",
    "At its most basic level, **machine learning is the process of taking data and using that data to create models**. We create these models using any one of [about a billion different machine learning algorithms](http://scikit-learn.org/stable/user_guide.html). We can then use these models to better understand our data, or make predictions.\n",
    "\n",
    "Don't worry if you don't understand this. The code is just for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A quick example: linear regression\n",
    "\n",
    "\n",
    "### We can take the following data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Othello table.\n",
    "df = pd.read_csv('data/othello.csv', index_col=0)\n",
    "\n",
    "# Plot our points.\n",
    "ax = df.plot.scatter(x='experience', y='salary')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And create a model from that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have experience and salary data. We have one row per person, and for each person we information on the number of years of experience and their salary. We will refer to each row as a **sample** or **observation**. We will refer to each column as an **attribute**, **dimension**, or **feature**.\n",
    "\n",
    "We can use the following algorithm:\n",
    "\n",
    "## ${\\hat {\\boldsymbol {\\beta }}}=(\\mathbf {X} ^{\\mathsf {T}}\\mathbf {X} )^{-1}\\mathbf {X} ^{\\mathsf {T}}\\mathbf {y} =\\left(\\sum \\mathbf {x} _{i}\\mathbf {x} _{i}^{\\mathsf {T}}\\right)^{-1}\\left(\\sum \\mathbf {x} _{i}y_{i}\\right)$\n",
    "\n",
    "... to create a [simple linear regression model](https://en.wikipedia.org/wiki/Simple_linear_regression) from our data. We **train** the algorithm (in other words feed it data), and we end up with a model which we can then use to make further predictions. We then **test** our algorithm to determine how good or bad it is.\n",
    "\n",
    "* Note: we will not be delving into the mathematics here--I don't have the time (or frankly the knowledge) to address this adequately. Just know that each machine learning algorithm for creating models is backed up with rather complex mathematics, and there are a billion YouTube videos that will explain this in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a linear regression. Note: inputs must be of the same length.\n",
    "linreg = LinearRegression()\n",
    "X = df['experience'].values.reshape(-1,1)\n",
    "y = df['salary'].values.reshape(-1,1)\n",
    "\n",
    "# Fit our model.\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# Get our coefficients.\n",
    "coeff = linreg.coef_[0][0].round(1)\n",
    "inter = linreg.predict(0)[0][0].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: everything with a trailiing underscore, like linreg.coef_ above, contains information from the fitted mode (i.e. will not be available prior to fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the formula in a pretty manner.\n",
    "display(Markdown('### Our model is summarized by the formula:<br>'))\n",
    "formula = 'y = {}x + {}'.format(coeff, inter)\n",
    "formula_string = '$' + formula + '$'\n",
    "display(Latex(formula_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then use this information new model to predict future observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict previously unseen information.\n",
    "EMILIA_EXPERIENCE = 25\n",
    "emilia_prediction = int(linreg.predict(EMILIA_EXPERIENCE)[0][0])\n",
    "emilia_string = 'E.g. if Emilia has {} years, she will probably make ${:,}.\\n'.format(EMILIA_EXPERIENCE, emilia_prediction)\n",
    "display(Markdown('#### ' + emilia_string))\n",
    "\n",
    "display(Markdown('#### Or we can predict a series of points ...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of predictions from 0 to 30.\n",
    "exp_range = np.arange(0,30).reshape(-1,1)\n",
    "sal_prediction = linreg.predict(exp_range)\n",
    "\n",
    "# Plot our old points\n",
    "ax1 = df.plot.scatter(x='experience', y='salary')\n",
    "\n",
    "# Plot our point range with formula\n",
    "plt.plot(exp_range, sal_prediction, linestyle='--')\n",
    "plt.annotate(formula, (5,300000))\n",
    "\n",
    "# Plot Emilia\n",
    "plt.plot(EMILIA_EXPERIENCE, emilia_prediction, 'ro')\n",
    "plt.annotate('Emilia', (EMILIA_EXPERIENCE, emilia_prediction - 50000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Well that wasn't very fancy now, was it?\n",
    "\n",
    "Well, erm ... no. It wasn't. This was a **univariate** problem, meaning it only had one variable (experience) as an input. Where ML shines with more complex **multivariate** problems, which we will get to. For example, what if all of our observations had data for: 1) years experience, 2) IQ, and 3) whether an individual graduated from college? How would that work?\n",
    "\n",
    "In order to adequately address those problems, we need to introduce some common terminology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised and Unsupervised Learning\n",
    "\n",
    "Two of the main types of ML algorithms can be classified as **supervised** or **unsupervised**--they are approached in fundementally different ways.\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, we do not provide the algorithm with any guidance as to what it is looking at. The algorithm has to categorize things completely based non-dependant inputs. An example of unsupervised learning would be [clustering algorithms](http://scikit-learn.org/stable/unsupervised_learning.html).\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "Supervised learning is the more useful for people getting started in ML, and consequently we will spend most of our time here. In supervised learning, we supply with data--**including the data that will eventually be predicting**.\n",
    "\n",
    "For a more concrete example, let's look at the canonical [Iris Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iris.csv')\n",
    "grid = sns.FacetGrid(data=df, hue='species', size=3)\n",
    "grid.map(plt.scatter, 'petal_length', 'petal_width').add_legend()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have data about how big certain parts of a flower are, and we also have information about the species of the flower. So what do we want to predict?\n",
    "\n",
    "One option would be to predict the species of flower based on the size of the flower parts. This would be a [**classification**](https://en.wikipedia.org/wiki/Statistical_classification) problem because our prediction would be a discrete category, such as 'setosa' or 'versicolor'.\n",
    "\n",
    "Another option would be to predict the size of a part of the flower based on the size of the other parts of the flower. This would be a [**regression**](https://en.wikipedia.org/wiki/Regression_analysis) problem because our prediction would be a continous variable, such as 1.5 or 2.1.\n",
    "\n",
    "In either case, our prediction will proceed in roughly the same way. We feed the model **feature vectors, denoted by an uppercase X** of the data we will be using to predict the species. We will also feed the model a **target vector, denoted by lowercase y** that will inform the model of what the 'right' answer is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## In practice\n",
    "\n",
    "Sklearn makes it's API pretty painless once you get a hang of it. It boils down to 3 main concepts:\n",
    "\n",
    "* **fit**: if you want your model to learn from the data, you call my_model.fit(X, y). After fitting you can then transform or predict.\n",
    "* **transform**: if you want to take inputs, change them, and then output them, you call my_model.transform(X). This can only be called after fitting the model.\n",
    "* **predict**: if you want predictions based on your data, you call my_model.predict(X). This can only be called after fitting the model.\n",
    "\n",
    "This gets even simpler when you put items in a pipeline. With a pipeline, you simply list all the operations you want to do, then you simply use fit() and predict() once for the entire collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification example: [K-Nearest Neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) classifier (often erroneously called ['clustering'](http://scikit-learn.org/stable/modules/clustering.html#k-means)).\n",
    "\n",
    "Our target vector is 'species', which is discrete.\n",
    "\n",
    "Our feature vectors are ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get our training vectors\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "\n",
    "# Then we get our target vector\n",
    "y = df['species']\n",
    "\n",
    "# Then create our classifier based on 3 nearest neighbors.\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Then fit the model with our data. \n",
    "knn.fit(X, y)\n",
    "\n",
    "# Then predict.\n",
    "test = [[6.5, 2.9, 5.5, 1.8]]\n",
    "prediction = knn.predict(test)\n",
    "print('Prediction for: {} is {}.'.format(test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression example: [Support Vector Machine](https://en.wikipedia.org/wiki/Support_vector_machine) Regressor:\n",
    "\n",
    "Our target vector is 'petal_width', which is continuous.\n",
    "\n",
    "Our feature vectors are ['sepal_length', 'sepal_width', 'petal_length']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get our training vectors\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length']]\n",
    "\n",
    "# Then we get our target vector\n",
    "y = df['petal_width']\n",
    "\n",
    "# Then create our classifier based on 3 nearest neighbors.\n",
    "svr = SVR()\n",
    "\n",
    "# Then fit the model with our data. \n",
    "svr.fit(X, y)\n",
    "\n",
    "# Then predict.\n",
    "test = [[6.5, 2.9, 5.5]]\n",
    "prediction = svr.predict(test)\n",
    "print('Prediction for: {} is {}.'.format(test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: you'll notice that there are brackets around our results. Usually when you're predicting something like this, it's a lot more efficient to do a bunch at once. Sklearn presumes that you want a list of results as your return type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reiterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='static/supervised_ml_flowchart_raw.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And in sklearn parlance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='static/supervised_ml_flowchart_annotated.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Learing Resources\n",
    "\n",
    "* ### [Scikit-Learn Quick Start](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "* ### [Scikit-Learn Tutorials](http://scikit-learn.org/stable/tutorial/index.html)\n",
    "* ### [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.00-machine-learning.html). Seriously. Read this.\n",
    "* ### [Getting Started with Scikit Learn (Part 1)](https://www.youtube.com/watch?v=L7R4HUQ-eQ0)\n",
    "* ### [Getting Started with Scikit Learn (Part 2)](https://www.youtube.com/watch?v=oGqGxvqA9-k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Next Up: [Preprocessing](3_preprocessing.ipynb)\n",
    "\n",
    "<br>\n",
    "\n",
    "<img style=\"margin-left: 0;\" src=\"static/log_transform.svg\" width=\"20%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='left'>\n",
    "    Image courtesy of <a href='https://commons.wikimedia.org/wiki/File:Population_vs_area.svg'>Skbkekas</a> under the <a href='https://creativecommons.org/licenses/by-sa/3.0/deed.en'>CC BY-SA 3.0</a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
